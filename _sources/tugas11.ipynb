{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4c86cf0b",
   "metadata": {},
   "source": [
    "# PERHITUNGAN JARAK 100 DATA SUARA BUKA/TUTUP DAN 1 DATA SUARA BARU MENGGUNAKAN DATA TIME WARPING\n",
    "\n",
    "Pada tugas ini, data suara yang saya gunakan masih sama dengan tugas sebelumnya. keseluruhan suara saya simpan di folder PSD-audio-wav, yaitu data suara yang telah dikonvert ke ekstensi wav dan terdiri dari suara yang mengucapkan buka atau tutup. Di dalam nya terdaoat 3 folder lain, pertama terdapat folder 'Suara1' yang berisi 50 data rekaman suara saya. folder ini terdiri dari 25 suara buka dengan label 'Perekaman baru 1' sampai dengan 'Perekaman label 25' dan terdiri dari 25 suara tutup dengan label 'Perekaman suara 26' sampai dengan 'Perekaman baru 50'. Folder kedua yaitu 'Suara2\" yang berisi 50 data suara teman saya. Folder ini terdiri dari 25 suara buka dengan label 'buka1' sampai dengan 'buka25' dan terdiri dari suara tutup dengan label 'tutup1' sampai dengan 'tutup25'. Ketiga ada folder 'suara-baru' yang terdiri dari 1 rekaman suara buka dengan label 'Perekaman baru 51'. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e3c729d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jumlah rekaman per folder:\n",
      "Folder\n",
      "Suara1        50\n",
      "Suara2        50\n",
      "suara-baru     1\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "base_path = \"PSD-audio-wav\"\n",
    "\n",
    "dataset_info = []\n",
    "\n",
    "folder1 = os.path.join(base_path, \"Suara1\")\n",
    "files1 = sorted(os.listdir(folder1))\n",
    "for i, f in enumerate(files1, start=1):\n",
    "    label = \"buka\" if i <= 25 else \"tutup\"\n",
    "    dataset_info.append([f, \"Suara1\", label])\n",
    "\n",
    "folder2 = os.path.join(base_path, \"Suara2\")\n",
    "files2 = sorted(os.listdir(folder2))\n",
    "for f in files2:\n",
    "    label = \"buka\" if f.lower().startswith(\"buka\") else \"tutup\"\n",
    "    dataset_info.append([f, \"Suara2\", label])\n",
    "\n",
    "folder3 = os.path.join(base_path, \"suara-baru\")\n",
    "files3 = sorted(os.listdir(folder3))\n",
    "for f in files3:\n",
    "    dataset_info.append([f, \"suara-baru\", \"Tidak Diketahui (Testing)\"])\n",
    "\n",
    "df_dataset = pd.DataFrame(dataset_info, columns=[\"Nama File\", \"Folder\", \"Label\"])\n",
    "\n",
    "jumlah_per_folder = df_dataset[\"Folder\"].value_counts()\n",
    "print(\"Jumlah rekaman per folder:\")\n",
    "print(jumlah_per_folder)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d2e5859",
   "metadata": {},
   "source": [
    "## 1. Import Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "77f551eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting fastdtw\n",
      "  Downloading fastdtw-0.3.4.tar.gz (133 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Requirement already satisfied: numpy in c:\\users\\vanisa\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from fastdtw) (2.3.3)\n",
      "Building wheels for collected packages: fastdtw\n",
      "  Building wheel for fastdtw (setup.py): started\n",
      "  Building wheel for fastdtw (setup.py): finished with status 'done'\n",
      "  Created wheel for fastdtw: filename=fastdtw-0.3.4-py3-none-any.whl size=3630 sha256=5a04f4bd8581967d78ec71a1b153d90f738a3c2f84ca38b2bd4677798b5d4a30\n",
      "  Stored in directory: c:\\users\\vanisa\\appdata\\local\\pip\\cache\\wheels\\2c\\9e\\6d\\6c419b5fe1b720cf2f9c7b20ea119dc201878ea890ba26221f\n",
      "Successfully built fastdtw\n",
      "Installing collected packages: fastdtw\n",
      "Successfully installed fastdtw-0.3.4\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  DEPRECATION: Building 'fastdtw' using the legacy setup.py bdist_wheel mechanism, which will be removed in a future version. pip 25.3 will enforce this behaviour change. A possible replacement is to use the standardized build interface by setting the `--use-pep517` option, (possibly combined with `--no-build-isolation`), or adding a `pyproject.toml` file to the source tree of 'fastdtw'. Discussion can be found at https://github.com/pypa/pip/issues/6334\n",
      "\n",
      "[notice] A new release of pip is available: 25.2 -> 25.3\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install fastdtw\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a8787d74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting python_speech_features\n",
      "  Downloading python_speech_features-0.6.tar.gz (5.6 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Building wheels for collected packages: python_speech_features\n",
      "  Building wheel for python_speech_features (setup.py): started\n",
      "  Building wheel for python_speech_features (setup.py): finished with status 'done'\n",
      "  Created wheel for python_speech_features: filename=python_speech_features-0.6-py3-none-any.whl size=5907 sha256=7bcfdac7b0c354c469e279a386c6213b79314b863db4fa8cabcc2907274d24cc\n",
      "  Stored in directory: c:\\users\\vanisa\\appdata\\local\\pip\\cache\\wheels\\6f\\9d\\a4\\f98b63d53ed4f9ea88655dac2933a0d2c5a18b2d3e9447d0b0\n",
      "Successfully built python_speech_features\n",
      "Installing collected packages: python_speech_features\n",
      "Successfully installed python_speech_features-0.6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  DEPRECATION: Building 'python_speech_features' using the legacy setup.py bdist_wheel mechanism, which will be removed in a future version. pip 25.3 will enforce this behaviour change. A possible replacement is to use the standardized build interface by setting the `--use-pep517` option, (possibly combined with `--no-build-isolation`), or adding a `pyproject.toml` file to the source tree of 'python_speech_features'. Discussion can be found at https://github.com/pypa/pip/issues/6334\n",
      "\n",
      "[notice] A new release of pip is available: 25.2 -> 25.3\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scipy in c:\\users\\vanisa\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (1.16.2)\n",
      "Requirement already satisfied: numpy<2.6,>=1.25.2 in c:\\users\\vanisa\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from scipy) (2.3.3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.2 -> 25.3\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install python_speech_features\n",
    "!pip install scipy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c5047ff9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import librosa\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from fastdtw import fastdtw\n",
    "from scipy.spatial.distance import euclidean\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import scipy.io.wavfile as wav\n",
    "import python_speech_features as psf\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07c1ef9e",
   "metadata": {},
   "source": [
    "## 2. Ekstraksi Audio dan MFCC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "058ee01c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io.wavfile as wav\n",
    "import python_speech_features as psf\n",
    "import numpy as np\n",
    "\n",
    "def extract_audio_features_no_numba(file_path, n_mfcc=13):\n",
    "    # Baca audio\n",
    "    sr, audio = wav.read(file_path)\n",
    "    \n",
    "    # Jika stereo, ambil salah satu channel\n",
    "    if len(audio.shape) == 2:\n",
    "        audio = audio[:, 0]\n",
    "    \n",
    "    # Normalisasi audio ke float (-1, 1)\n",
    "    audio = audio / np.max(np.abs(audio))\n",
    "    \n",
    "    # Ekstraksi MFCC\n",
    "    mfcc = psf.mfcc(audio, samplerate=sr, numcep=n_mfcc)\n",
    "    \n",
    "    return audio, mfcc, sr\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0359af8e",
   "metadata": {},
   "source": [
    "## 3. Load Data Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5c6f19a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:frame length (1200) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n",
      "WARNING:root:frame length (1200) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n",
      "WARNING:root:frame length (1200) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n",
      "WARNING:root:frame length (1200) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n",
      "WARNING:root:frame length (1200) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n",
      "WARNING:root:frame length (1200) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n",
      "WARNING:root:frame length (1200) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n",
      "WARNING:root:frame length (1200) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n",
      "WARNING:root:frame length (1200) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n",
      "WARNING:root:frame length (1200) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n",
      "WARNING:root:frame length (1200) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n",
      "WARNING:root:frame length (1200) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n",
      "WARNING:root:frame length (1200) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n",
      "WARNING:root:frame length (1200) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n",
      "WARNING:root:frame length (1200) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n",
      "WARNING:root:frame length (1200) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n",
      "WARNING:root:frame length (1200) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n",
      "WARNING:root:frame length (1200) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n",
      "WARNING:root:frame length (1200) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n",
      "WARNING:root:frame length (1200) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n",
      "WARNING:root:frame length (1200) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n",
      "WARNING:root:frame length (1200) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n",
      "WARNING:root:frame length (1200) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n",
      "WARNING:root:frame length (1200) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n",
      "WARNING:root:frame length (1200) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n",
      "WARNING:root:frame length (1200) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n",
      "WARNING:root:frame length (1200) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n",
      "WARNING:root:frame length (1200) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n",
      "WARNING:root:frame length (1200) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n",
      "WARNING:root:frame length (1200) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n",
      "WARNING:root:frame length (1200) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n",
      "WARNING:root:frame length (1200) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n",
      "WARNING:root:frame length (1200) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n",
      "WARNING:root:frame length (1200) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n",
      "WARNING:root:frame length (1200) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n",
      "WARNING:root:frame length (1200) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n",
      "WARNING:root:frame length (1200) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n",
      "WARNING:root:frame length (1200) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n",
      "WARNING:root:frame length (1200) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n",
      "WARNING:root:frame length (1200) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n",
      "WARNING:root:frame length (1200) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n",
      "WARNING:root:frame length (1200) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n",
      "WARNING:root:frame length (1200) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n",
      "WARNING:root:frame length (1200) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n",
      "WARNING:root:frame length (1200) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n",
      "WARNING:root:frame length (1200) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n",
      "WARNING:root:frame length (1200) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n",
      "WARNING:root:frame length (1200) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n",
      "WARNING:root:frame length (1200) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n",
      "WARNING:root:frame length (1200) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>filename</th>\n",
       "      <th>label</th>\n",
       "      <th>length_time_series</th>\n",
       "      <th>mfcc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>buka 1.wav</td>\n",
       "      <td>buka</td>\n",
       "      <td>129</td>\n",
       "      <td>[[-36.04365338911715, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>buka10.wav</td>\n",
       "      <td>buka</td>\n",
       "      <td>198</td>\n",
       "      <td>[[-36.04365338911715, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>buka11.wav</td>\n",
       "      <td>buka</td>\n",
       "      <td>234</td>\n",
       "      <td>[[-36.04365338911715, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>buka12.wav</td>\n",
       "      <td>buka</td>\n",
       "      <td>222</td>\n",
       "      <td>[[-36.04365338911715, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>buka13.wav</td>\n",
       "      <td>buka</td>\n",
       "      <td>193</td>\n",
       "      <td>[[-36.04365338911715, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id    filename label  length_time_series  \\\n",
       "0   1  buka 1.wav  buka                 129   \n",
       "1   2  buka10.wav  buka                 198   \n",
       "2   3  buka11.wav  buka                 234   \n",
       "3   4  buka12.wav  buka                 222   \n",
       "4   5  buka13.wav  buka                 193   \n",
       "\n",
       "                                                mfcc  \n",
       "0  [[-36.04365338911715, 0.0, 0.0, 0.0, 0.0, 0.0,...  \n",
       "1  [[-36.04365338911715, 0.0, 0.0, 0.0, 0.0, 0.0,...  \n",
       "2  [[-36.04365338911715, 0.0, 0.0, 0.0, 0.0, 0.0,...  \n",
       "3  [[-36.04365338911715, 0.0, 0.0, 0.0, 0.0, 0.0,...  \n",
       "4  [[-36.04365338911715, 0.0, 0.0, 0.0, 0.0, 0.0,...  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "folder_train = \"PSD-audio-wav/Suara2\"\n",
    "train_files = sorted(os.listdir(folder_train))\n",
    "\n",
    "dataset = []\n",
    "\n",
    "for i, f in enumerate(train_files):\n",
    "    path = os.path.join(folder_train, f)\n",
    "    audio, mfcc, sr = extract_audio_features_no_numba(path)\n",
    "    \n",
    "    label = \"buka\" if f.lower().startswith(\"buka\") else \"tutup\"\n",
    "    \n",
    "    dataset.append({\n",
    "        \"id\": i+1,\n",
    "        \"filename\": f,\n",
    "        \"label\": label,\n",
    "        \"length_time_series\": len(mfcc),\n",
    "        \"mfcc\": mfcc\n",
    "    })\n",
    "\n",
    "df_metadata = pd.DataFrame(dataset)\n",
    "df_metadata.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cd9fd81",
   "metadata": {},
   "source": [
    "## 4. Load Data Baru"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8a889650",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Audio mentah: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] ...\n",
      "Sampling rate: 48000\n",
      "Panjang audio (samples): 112640\n"
     ]
    }
   ],
   "source": [
    "def load_audio(file_path, target_sr=16000):\n",
    "    # Load audio mentah dan resample\n",
    "    audio, sr = librosa.load(file_path, sr=target_sr)\n",
    "    return audio, sr\n",
    "\n",
    "test_file = \"PSD-audio-wav/Suara-baru/Perekaman baru 51.wav\"\n",
    "print(f\"Audio mentah: {test_audio[:10]} ...\")  \n",
    "print(f\"Sampling rate: {sr}\")\n",
    "print(f\"Panjang audio (samples): {len(test_audio)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "279b10e0",
   "metadata": {},
   "source": [
    "## 5. Normalisasi dan MFCC\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c161bf3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:frame length (1200) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Panjang time series (MFCC): 234\n"
     ]
    }
   ],
   "source": [
    "def extract_mfcc(audio, sr, n_mfcc=13, nfft=512):\n",
    "    # Normalisasi\n",
    "    audio_norm = audio / np.max(np.abs(audio))\n",
    "    \n",
    "    # Ekstrak MFCC\n",
    "    mfcc = psf.mfcc(audio_norm, samplerate=sr, numcep=n_mfcc, nfft=nfft)\n",
    "    \n",
    "    return mfcc\n",
    "\n",
    "test_mfcc = extract_mfcc(test_audio, sr)\n",
    "print(f\"Panjang time series (MFCC): {len(test_mfcc)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "84514801",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'numba' has no attribute 'core'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[21]\u001b[39m\u001b[32m, line 37\u001b[39m\n\u001b[32m     34\u001b[39m test_file = \u001b[33m\"\u001b[39m\u001b[33mPSD-audio-wav/Suara-baru/Perekaman baru 51.wav\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     36\u001b[39m \u001b[38;5;66;03m# 1️⃣ Load audio mentah\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m37\u001b[39m test_audio, sr = \u001b[43mload_audio\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_file\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     38\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mAudio mentah (10 sample pertama): \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtest_audio[:\u001b[32m10\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m ...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     39\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mSampling rate: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msr\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[21]\u001b[39m\u001b[32m, line 12\u001b[39m, in \u001b[36mload_audio\u001b[39m\u001b[34m(file_path, target_sr)\u001b[39m\n\u001b[32m      8\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mload_audio\u001b[39m(file_path, target_sr=\u001b[32m16000\u001b[39m):\n\u001b[32m      9\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     10\u001b[39m \u001b[33;03m    Load audio mentah dan resample ke target_sr\u001b[39;00m\n\u001b[32m     11\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m12\u001b[39m     audio, sr = \u001b[43mlibrosa\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload\u001b[49m(file_path, sr=target_sr)\n\u001b[32m     13\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m audio, sr\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\vanisa\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\lazy_loader\\__init__.py:83\u001b[39m, in \u001b[36mattach.<locals>.__getattr__\u001b[39m\u001b[34m(name)\u001b[39m\n\u001b[32m     81\u001b[39m submod_path = \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpackage_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mattr_to_modules[name]\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m     82\u001b[39m submod = importlib.import_module(submod_path)\n\u001b[32m---> \u001b[39m\u001b[32m83\u001b[39m attr = \u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msubmod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     85\u001b[39m \u001b[38;5;66;03m# If the attribute lives in a file (module) with the same\u001b[39;00m\n\u001b[32m     86\u001b[39m \u001b[38;5;66;03m# name as the attribute, ensure that the attribute and *not*\u001b[39;00m\n\u001b[32m     87\u001b[39m \u001b[38;5;66;03m# the module is accessible on the package.\u001b[39;00m\n\u001b[32m     88\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m name == attr_to_modules[name]:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\vanisa\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\lazy_loader\\__init__.py:82\u001b[39m, in \u001b[36mattach.<locals>.__getattr__\u001b[39m\u001b[34m(name)\u001b[39m\n\u001b[32m     80\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m attr_to_modules:\n\u001b[32m     81\u001b[39m     submod_path = \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpackage_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mattr_to_modules[name]\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m---> \u001b[39m\u001b[32m82\u001b[39m     submod = \u001b[43mimportlib\u001b[49m\u001b[43m.\u001b[49m\u001b[43mimport_module\u001b[49m\u001b[43m(\u001b[49m\u001b[43msubmod_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     83\u001b[39m     attr = \u001b[38;5;28mgetattr\u001b[39m(submod, name)\n\u001b[32m     85\u001b[39m     \u001b[38;5;66;03m# If the attribute lives in a file (module) with the same\u001b[39;00m\n\u001b[32m     86\u001b[39m     \u001b[38;5;66;03m# name as the attribute, ensure that the attribute and *not*\u001b[39;00m\n\u001b[32m     87\u001b[39m     \u001b[38;5;66;03m# the module is accessible on the package.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\vanisa\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\importlib\\__init__.py:88\u001b[39m, in \u001b[36mimport_module\u001b[39m\u001b[34m(name, package)\u001b[39m\n\u001b[32m     86\u001b[39m             \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m     87\u001b[39m         level += \u001b[32m1\u001b[39m\n\u001b[32m---> \u001b[39m\u001b[32m88\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_bootstrap\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_gcd_import\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m[\u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpackage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen importlib._bootstrap>:1387\u001b[39m, in \u001b[36m_gcd_import\u001b[39m\u001b[34m(name, package, level)\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen importlib._bootstrap>:1360\u001b[39m, in \u001b[36m_find_and_load\u001b[39m\u001b[34m(name, import_)\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen importlib._bootstrap>:1331\u001b[39m, in \u001b[36m_find_and_load_unlocked\u001b[39m\u001b[34m(name, import_)\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen importlib._bootstrap>:935\u001b[39m, in \u001b[36m_load_unlocked\u001b[39m\u001b[34m(spec)\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen importlib._bootstrap_external>:1026\u001b[39m, in \u001b[36mexec_module\u001b[39m\u001b[34m(self, module)\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen importlib._bootstrap>:488\u001b[39m, in \u001b[36m_call_with_frames_removed\u001b[39m\u001b[34m(f, *args, **kwds)\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\vanisa\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\librosa\\core\\audio.py:18\u001b[39m\n\u001b[32m     15\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msoxr\u001b[39;00m\n\u001b[32m     16\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlazy_loader\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlazy\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m18\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnumba\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m jit, stencil, guvectorize\n\u001b[32m     19\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mfft\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m get_fftlib\n\u001b[32m     20\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mconvert\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m frames_to_samples, time_to_samples\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\vanisa\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\numba\\__init__.py:74\u001b[39m\n\u001b[32m     70\u001b[39m \u001b[38;5;28;01mdel\u001b[39;00m generate_version_info\n\u001b[32m     73\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnumba\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcore\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m config\n\u001b[32m---> \u001b[39m\u001b[32m74\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnumba\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcore\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m types, errors\n\u001b[32m     76\u001b[39m \u001b[38;5;66;03m# Re-export typeof\u001b[39;00m\n\u001b[32m     77\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnumba\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmisc\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mspecial\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     78\u001b[39m     typeof, prange, pndindex, gdb, gdb_breakpoint, gdb_init,\n\u001b[32m     79\u001b[39m     literally, literal_unroll,\n\u001b[32m     80\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\vanisa\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\numba\\core\\types\\__init__.py:7\u001b[39m\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnumba\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcore\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m utils\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mabstract\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m *\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcontainers\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m *\n\u001b[32m      8\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mfunctions\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m *\n\u001b[32m      9\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01miterators\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m *\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\vanisa\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\numba\\core\\types\\containers.py:23\u001b[39m\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mabstract\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m      6\u001b[39m     ConstSized,\n\u001b[32m      7\u001b[39m     Container,\n\u001b[32m   (...)\u001b[39m\u001b[32m     15\u001b[39m     Poison,\n\u001b[32m     16\u001b[39m )\n\u001b[32m     17\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcommon\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     18\u001b[39m     Buffer,\n\u001b[32m     19\u001b[39m     IterableType,\n\u001b[32m     20\u001b[39m     SimpleIterableType,\n\u001b[32m     21\u001b[39m     SimpleIteratorType,\n\u001b[32m     22\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m23\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmisc\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Undefined, unliteral, Optional, NoneType\n\u001b[32m     24\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mtypeconv\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Conversion\n\u001b[32m     25\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01merrors\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m TypingError\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\vanisa\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\numba\\core\\types\\misc.py:6\u001b[39m\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnumba\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcore\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mtypeconv\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Conversion\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnumba\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcore\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01merrors\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m TypingError, LiteralTypingError\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnumba\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcore\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mir\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m UndefinedType\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnumba\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcore\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m get_hashable_key\n\u001b[32m     10\u001b[39m \u001b[38;5;28;01mclass\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mPyObject\u001b[39;00m(Dummy):\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\vanisa\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\numba\\core\\ir.py:22\u001b[39m\n\u001b[32m     19\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnumba\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcore\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m consts\n\u001b[32m     21\u001b[39m \u001b[38;5;66;03m# terminal color markup\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m22\u001b[39m _termcolor = \u001b[43merrors\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtermcolor\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     25\u001b[39m \u001b[38;5;28;01mclass\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mLoc\u001b[39;00m(\u001b[38;5;28mobject\u001b[39m):\n\u001b[32m     26\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Source location\u001b[39;00m\n\u001b[32m     27\u001b[39m \n\u001b[32m     28\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\vanisa\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\numba\\core\\errors.py:352\u001b[39m, in \u001b[36mtermcolor\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    350\u001b[39m \u001b[38;5;28;01mglobal\u001b[39;00m _termcolor_inst\n\u001b[32m    351\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m _termcolor_inst \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m352\u001b[39m     scheme = themes[\u001b[43mnumba\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcore\u001b[49m.config.COLOR_SCHEME]\n\u001b[32m    353\u001b[39m     _termcolor_inst = HighlightColorScheme(scheme)\n\u001b[32m    354\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m _termcolor_inst\n",
      "\u001b[31mAttributeError\u001b[39m: module 'numba' has no attribute 'core'"
     ]
    }
   ],
   "source": [
    "import librosa\n",
    "import numpy as np\n",
    "import python_speech_features as psf\n",
    "\n",
    "# ===============================\n",
    "# Fungsi untuk load audio mentah\n",
    "# ===============================\n",
    "def load_audio(file_path, target_sr=16000):\n",
    "    \"\"\"\n",
    "    Load audio mentah dan resample ke target_sr\n",
    "    \"\"\"\n",
    "    audio, sr = librosa.load(file_path, sr=target_sr)\n",
    "    return audio, sr\n",
    "\n",
    "# ===============================\n",
    "# Fungsi untuk ekstraksi MFCC + normalisasi\n",
    "# ===============================\n",
    "def extract_mfcc(audio, sr, n_mfcc=13, nfft=2048):\n",
    "    \"\"\"\n",
    "    Normalisasi audio dan ekstrak MFCC\n",
    "    nfft diperbesar untuk menghindari warning\n",
    "    \"\"\"\n",
    "    # Normalisasi audio (-1 sampai 1)\n",
    "    audio_norm = audio / np.max(np.abs(audio))\n",
    "    \n",
    "    # Ekstrak MFCC\n",
    "    mfcc = psf.mfcc(audio_norm, samplerate=sr, numcep=n_mfcc, nfft=nfft)\n",
    "    \n",
    "    return mfcc\n",
    "\n",
    "# ===============================\n",
    "# Load file audio baru\n",
    "# ===============================\n",
    "test_file = \"PSD-audio-wav/Suara-baru/Perekaman baru 51.wav\"\n",
    "\n",
    "# 1️⃣ Load audio mentah\n",
    "test_audio, sr = load_audio(test_file)\n",
    "print(f\"Audio mentah (10 sample pertama): {test_audio[:10]} ...\")\n",
    "print(f\"Sampling rate: {sr}\")\n",
    "print(f\"Panjang audio (samples): {len(test_audio)}\")\n",
    "\n",
    "# 2️⃣ Normalisasi + ekstraksi MFCC (nfft lebih besar)\n",
    "test_mfcc = extract_mfcc(test_audio, sr, n_mfcc=13, nfft=2048)\n",
    "print(f\"Panjang time series (MFCC): {len(test_mfcc)}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
